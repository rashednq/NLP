{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "669a3790",
   "metadata": {},
   "source": [
    "# Information Retrieval\n",
    "\n",
    "## Overview\n",
    "\n",
    "This lab provides hands-on practice building a complete **Search Engine** from scratch using **TF-IDF (Term Frequency-Inverse Document Frequency)**, one of the most common techniques in Information Retrieval. You'll work with real datasets, implement TF-IDF vectorization, measure document similarity using cosine similarity, and build a functional search engine that can retrieve and rank documents based on user queries. This lab demonstrates the practical application of IR concepts in building production-ready search systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54002715",
   "metadata": {},
   "source": [
    "> A 2015 survey showed that 83% of text-based recommender systems in digital libraries used TF-IDF.\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. **Setup and Imports** - Installing dependencies and importing libraries\n",
    "2. **Dataset Loading** - Loading the 20 Newsgroups dataset from scikit-learn\n",
    "3. **Text Preprocessing** - Preparing documents for vectorization\n",
    "4. **TF-IDF Vectorization** - Converting documents and queries into numerical vectors\n",
    "5. **Building the Search Engine**:\n",
    "   - **Retrieval**: Finding the most similar documents to a query using cosine similarity\n",
    "   - **Ranking**: Ordering documents by relevance score\n",
    "   - **Classification**: Classifying queries into one of the 20 categories\n",
    "6. **Testing the Search Engine** - Querying and evaluating results\n",
    "7. **Understanding Results** - Interpreting search results and similarity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4a535e",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Recognize the term-document matrix produced by the TF-IDF algorithm\n",
    "- Understand how similarity is measured between text vectors (cosine similarity)\n",
    "- **Work with real datasets**.\n",
    "- **Implement a TF-IDF-based search engine** using:\n",
    "  - Scikit-learn's `TfidfVectorizer`\n",
    "  - Cosine similarity for document ranking\n",
    "  - Sparse matrices for efficient storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff080ff",
   "metadata": {},
   "source": [
    "## Glossary of Terms\n",
    "\n",
    "**Information Retrieval (IR)**: The task of finding information (usually documents) that satisfies an information need from within large collections.\n",
    "\n",
    "**Corpus**: A collection of documents. In IR, this is the entire set of documents we search through.\n",
    "\n",
    "**Query**: A user's information need expressed in natural language (e.g., \"What is machine learning?\").\n",
    "\n",
    "**Document**: A unit of information in the corpus (e.g., a web page, article, or text passage).\n",
    "\n",
    "**TF-IDF (Term Frequency-Inverse Document Frequency)**: A numerical statistic that reflects how important a word is to a document in a collection. As you learned in the vectorization lesson:\n",
    "- **TF (Term Frequency)**: How often a term appears in a document\n",
    "- **IDF (Inverse Document Frequency)**: How rare or common a term is across the entire corpus\n",
    "- **TF-IDF**: TF × IDF, giving higher weight to terms that are frequent in a document but rare in the corpus\n",
    "\n",
    "**Vector Space Model**: A model where documents and queries are represented as vectors in a high-dimensional space. Similarity is measured using the angle between vectors (cosine similarity).\n",
    "\n",
    "**Cosine Similarity**: A measure of similarity between two vectors. It measures the cosine of the angle between them, ranging from -1 to 1 (or 0 to 1 for non-negative vectors like TF-IDF).\n",
    "\n",
    "**Sparse Matrix**: A matrix where most elements are zero. TF-IDF vectors are typically sparse because most words don't appear in most documents.\n",
    "\n",
    "**Retrieval**: The process of finding and ranking documents in response to a query.\n",
    "\n",
    "**Ranking**: Ordering retrieved documents by their relevance score (highest to lowest)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c451be65",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [20 Newsgroups Dataset](https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset)\n",
    "- [Scikit-learn TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "- [Scikit-learn cosine_similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73007603",
   "metadata": {},
   "source": [
    "## The Complete Pipeline\n",
    "\n",
    "1. **Dataset Loading**: Load the 20 Newsgroups dataset from scikit-learn\n",
    "2. **Text Preprocessing**: Prepare documents for vectorization (as learned in previous lessons)\n",
    "3. **TF-IDF Vectorization**: Convert documents and queries into numerical vectors\n",
    "4. Model:\n",
    "   1. **Retrieval**: Find the most similar documents to a query using **cosine similarity**\n",
    "   2. **Classification**: Classify a query into one of the 20 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e643e",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "We group imports by category following Python best practices. All libraries used here are part of the standard scikit-learn ecosystem:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File > Open Folder > W5_NLP\n",
    "# (VS Code root should be at W5_NLP)\n",
    "# Then run: `uv sync`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f436a2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3172c8",
   "metadata": {},
   "source": [
    "## Loading the 20 Newsgroups Dataset\n",
    "\n",
    "We'll use scikit-learn's **20 Newsgroups dataset**, a collection of approximately 20,000 newsgroup documents, partitioned across 20 different newsgroups. This is a classic dataset for text classification and information retrieval experiments.\n",
    "\n",
    "**About the Dataset:**\n",
    "- **20 categories** of newsgroups (e.g., comp.graphics, rec.sport.baseball, sci.med)\n",
    "- Each document is a newsgroup post with subject and body text\n",
    "- Documents are organized by topic, which we'll use to create relevance judgments\n",
    "\n",
    "We'll load the 20 Newsgroups dataset using scikit-learn's `fetch_20newsgroups` function. This dataset contains newsgroup posts organized into 20 categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48eb4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c6705ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "fetch_20newsgroups(\n",
      "    *,\n",
      "    data_home=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    subset=\u001b[33m'train'\u001b[39m,\n",
      "    categories=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    random_state=\u001b[32m42\u001b[39m,\n",
      "    remove=(),\n",
      "    download_if_missing=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    return_X_y=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    n_retries=\u001b[32m3\u001b[39m,\n",
      "    delay=\u001b[32m1.0\u001b[39m,\n",
      ")\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Load the filenames and data from the 20 newsgroups dataset (classification).\n",
      "\n",
      "Download it if necessary.\n",
      "\n",
      "=================   ==========\n",
      "Classes                     20\n",
      "Samples total            18846\n",
      "Dimensionality               1\n",
      "Features                  text\n",
      "=================   ==========\n",
      "\n",
      "Read more in the :ref:`User Guide <20newsgroups_dataset>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "data_home : str or path-like, default=None\n",
      "    Specify a download and cache folder for the datasets. If None,\n",
      "    all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "\n",
      "subset : {'train', 'test', 'all'}, default='train'\n",
      "    Select the dataset to load: 'train' for the training set, 'test'\n",
      "    for the test set, 'all' for both, with shuffled ordering.\n",
      "\n",
      "categories : array-like, dtype=str, default=None\n",
      "    If None (default), load all the categories.\n",
      "    If not None, list of category names to load (other categories\n",
      "    ignored).\n",
      "\n",
      "shuffle : bool, default=True\n",
      "    Whether or not to shuffle the data: might be important for models that\n",
      "    make the assumption that the samples are independent and identically\n",
      "    distributed (i.i.d.), such as stochastic gradient descent.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=42\n",
      "    Determines random number generation for dataset shuffling. Pass an int\n",
      "    for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "remove : tuple, default=()\n",
      "    May contain any subset of ('headers', 'footers', 'quotes'). Each of\n",
      "    these are kinds of text that will be detected and removed from the\n",
      "    newsgroup posts, preventing classifiers from overfitting on\n",
      "    metadata.\n",
      "\n",
      "    'headers' removes newsgroup headers, 'footers' removes blocks at the\n",
      "    ends of posts that look like signatures, and 'quotes' removes lines\n",
      "    that appear to be quoting another post.\n",
      "\n",
      "    'headers' follows an exact standard; the other filters are not always\n",
      "    correct.\n",
      "\n",
      "download_if_missing : bool, default=True\n",
      "    If False, raise an OSError if the data is not locally available\n",
      "    instead of trying to download the data from the source site.\n",
      "\n",
      "return_X_y : bool, default=False\n",
      "    If True, returns `(data.data, data.target)` instead of a Bunch\n",
      "    object.\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "n_retries : int, default=3\n",
      "    Number of retries when HTTP errors are encountered.\n",
      "\n",
      "    .. versionadded:: 1.5\n",
      "\n",
      "delay : float, default=1.0\n",
      "    Number of seconds between retries.\n",
      "\n",
      "    .. versionadded:: 1.5\n",
      "\n",
      "Returns\n",
      "-------\n",
      "bunch : :class:`~sklearn.utils.Bunch`\n",
      "    Dictionary-like object, with the following attributes.\n",
      "\n",
      "    data : list of shape (n_samples,)\n",
      "        The data list to learn.\n",
      "    target: ndarray of shape (n_samples,)\n",
      "        The target labels.\n",
      "    filenames: list of shape (n_samples,)\n",
      "        The path to the location of the data.\n",
      "    DESCR: str\n",
      "        The full description of the dataset.\n",
      "    target_names: list of shape (n_classes,)\n",
      "        The names of target classes.\n",
      "\n",
      "(data, target) : tuple if `return_X_y=True`\n",
      "    A tuple of two ndarrays. The first contains a 2D array of shape\n",
      "    (n_samples, n_classes) with each row representing one sample and each\n",
      "    column representing the features. The second array of shape\n",
      "    (n_samples,) contains the target samples.\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.datasets import fetch_20newsgroups\n",
      ">>> cats = ['alt.atheism', 'sci.space']\n",
      ">>> newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
      ">>> list(newsgroups_train.target_names)\n",
      "['alt.atheism', 'sci.space']\n",
      ">>> newsgroups_train.filenames.shape\n",
      "(1073,)\n",
      ">>> newsgroups_train.target.shape\n",
      "(1073,)\n",
      ">>> newsgroups_train.target[:10]\n",
      "array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\rashe\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\sklearn\\datasets\\_twenty_newsgroups.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "fetch_20newsgroups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bb6422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 Newsgroups dataset...\n"
     ]
    }
   ],
   "source": [
    "# Load the 20 Newsgroups dataset\n",
    "# We'll use the training set as our document collection\n",
    "# remove=('headers', 'footers', 'quotes') removes metadata to focus on content\n",
    "print(\"Loading 20 Newsgroups dataset...\")\n",
    "newsgroups = fetch_20newsgroups(\n",
    "    subset='train',\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de287d",
   "metadata": {},
   "source": [
    "### Exercise 1: Explore the Dataset\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- The distribution of documents across categories\n",
    "- The content of sample documents\n",
    "- Notice that documents are organized by topic (category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbd2d2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category  \\\n",
       "0  I was wondering if anyone out there could enli...         7   \n",
       "1  A fair number of brave souls who upgraded thei...         4   \n",
       "2  well folks, my mac plus finally gave up the gh...         4   \n",
       "3  \\nDo you have Weitek's address/phone number?  ...         1   \n",
       "4  From article <C5owCB.n3p@world.std.com>, by to...        14   \n",
       "\n",
       "           category_name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'text': newsgroups.data,\n",
    "    'category': newsgroups.target,\n",
    "    'category_name': [newsgroups.target_names[newsgroups.target[i]] for i in range(len(newsgroups.target))]\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e998e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='category'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1145aece",
   "metadata": {},
   "source": [
    "### Drop columns and keep `text` only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411a5b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>I have a (very old) Mac 512k and a Mac Plus, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>Stolen from Pasadena between 4:30 and 6:30 pm ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      I was wondering if anyone out there could enli...\n",
       "1      A fair number of brave souls who upgraded thei...\n",
       "2      well folks, my mac plus finally gave up the gh...\n",
       "3      \\nDo you have Weitek's address/phone number?  ...\n",
       "4      From article <C5owCB.n3p@world.std.com>, by to...\n",
       "...                                                  ...\n",
       "11309  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...\n",
       "11310  I have a (very old) Mac 512k and a Mac Plus, b...\n",
       "11311  I just installed a DX2-66 CPU in a clone mothe...\n",
       "11312  \\nWouldn't this require a hyper-sphere.  In 3-...\n",
       "11313  Stolen from Pasadena between 4:30 and 6:30 pm ...\n",
       "\n",
       "[11314 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['text']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f92865",
   "metadata": {},
   "source": [
    "## Building the Search Engine\n",
    "\n",
    "Now we'll build a TF-IDF-based search engine. The process involves:\n",
    "\n",
    "1. **Creating TF-IDF vectors** for all documents\n",
    "2. **Implementing a retrieval function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c31e6",
   "metadata": {},
   "source": [
    "### How TF-IDF enables retrieval\n",
    "\n",
    "- TF-IDF weights words by their importance: rare words that appear frequently in a document get high scores\n",
    "- When a user searches for \"machine learning\", documents with high TF-IDF scores for those terms are likely relevant\n",
    "- The query is also converted to a TF-IDF vector, then compared to all document vectors\n",
    "\n",
    "**Cosine Similarity for Document Matching**\n",
    "\n",
    "To find relevant documents, we need to measure **similarity** between the query vector and document vectors. \n",
    "\n",
    "**Cosine Similarity** measures the angle between two vectors:\n",
    "- It ranges from -1 to 1 (or 0 to 1 for non-negative vectors like TF-IDF)\n",
    "- **1.0** = vectors point in the same direction (very similar)\n",
    "- **0.0** = vectors are perpendicular (no similarity)\n",
    "- **-1.0** = vectors point in opposite directions (very dissimilar)\n",
    "\n",
    "**Why cosine similarity?**\n",
    "- It measures similarity in **direction**, not magnitude\n",
    "- A long document and a short document about the same topic will have similar directions (high cosine similarity)\n",
    "- It's robust to document length differences\n",
    "- Works well with sparse TF-IDF vectors\n",
    "\n",
    "**The retrieval process:**\n",
    "1. Convert query to TF-IDF vector (using the same vocabulary as documents)\n",
    "2. Compute cosine similarity between query vector and all document vectors\n",
    "3. Rank documents by similarity score (highest first)\n",
    "4. Return top-k most similar documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa43bc",
   "metadata": {},
   "source": [
    "### Task 1: Creating TF-IDF vectors for all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e636eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create TF-IDF vectors for all documents\n",
    "# Initialize the vectorizer\n",
    "# We use default settings, but you can customize:\n",
    "# - max_features: limit vocabulary size\n",
    "# - stop_words: remove common words ('english')\n",
    "# - ngram_range: use unigrams and bigrams\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,      # Convert to lowercase\n",
    "    stop_words='english', # Remove English stop words\n",
    "    max_features=5000,   # Limit vocabulary to top 5000 terms\n",
    "    ngram_range=(1, 2)   # Use both unigrams and bigrams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33a74b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 504091 stored elements and shape (11314, 5000)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on all documents and transform them\n",
    "# This learns the vocabulary and IDF from the corpus\n",
    "document_vectors = vectorizer.fit_transform(df['text'])\n",
    "document_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "554ee14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document vectors shape: (11314, 5000)\n",
      "  - 11314 documents\n",
      "  - 5000 features (terms in vocabulary)\n",
      "\n",
      "This is a sparse matrix. Let's check sparsity:\n",
      "  - Non-zero elements: 504,091\n",
      "  - Total elements: 56,570,000\n",
      "  - Sparsity: 99.11%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Document vectors shape: {document_vectors.shape}\")\n",
    "print(f\"  - {document_vectors.shape[0]} documents\")\n",
    "print(f\"  - {document_vectors.shape[1]} features (terms in vocabulary)\")\n",
    "print(\"\\nThis is a sparse matrix. Let's check sparsity:\")\n",
    "print(f\"  - Non-zero elements: {document_vectors.nnz:,}\")\n",
    "print(f\"  - Total elements: {document_vectors.shape[0] * document_vectors.shape[1]:,}\")\n",
    "print(f\"  - Sparsity: {(1 - document_vectors.nnz / (document_vectors.shape[0] * document_vectors.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da4cf8",
   "metadata": {},
   "source": [
    "> Notice how the sparse matrix efficiently stores only non-zero values. This is why TF-IDF scales well to large document collections.\n",
    "\n",
    "- Document vectors shape: (~11,000, 5000) - thousands of documents, 5000 features\n",
    "- High sparsity (typically 95-99%) - most values are zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70896f34",
   "metadata": {},
   "source": [
    "Notice how there is a lot of junk in the text, when we print the vocabulary from `200:400`, this may or may not be useful, depending on your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc50001d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['42' '43' '44' '45' '46' '47' '48' '486' '49' '4e' '4k' '4l' '4t' '4th'\n",
      " '4u' '50' '500' '5000' '51' '52' '53' '54' '55' '56' '57' '58' '59' '5g'\n",
      " '5g9p' '5g9v' '5k' '5s' '5u' '60' '600' '6000' '61' '617' '62' '63' '64'\n",
      " '65' '650' '66' '67' '68' '69' '6e' '6ei' '6ei 6ei' '6g' '6um' '6um 6um'\n",
      " '70' '700' '703' '71' '72' '73' '74' '75' '750' '75u' '75u 75u' '76' '77'\n",
      " '78' '79' '7ex' '7ey' '7ey 7ey' '7ez' '7klj' '7kn' '7t' '7th' '7u' '80'\n",
      " '80 bit' '800' '81' '82' '83' '84' '85' '86' '87' '88' '89' '8n' '8v'\n",
      " '90' '900' '91' '91 92' '92' '93' '94' '95' '96' '97' '98' '99' '9d' '9f'\n",
      " '9f8' '9f9' '9l' '9l3' '9p' '9s' '9v' '9v g9v' '__' '___' '____' '_____'\n",
      " '_q' '_the' 'a4' 'a7' 'a86' 'a86 a86' 'a86 lg' 'a86r' 'ab' 'abc'\n",
      " 'abiding' 'ability' 'able' 'abortion' 'abs' 'absolute' 'absolutely'\n",
      " 'abuse' 'ac' 'ac uk' 'academic' 'accelerator' 'accept' 'acceptable'\n",
      " 'accepted' 'access' 'accident' 'accidents' 'accomplished' 'according'\n",
      " 'account' 'accounts' 'accurate' 'achieve' 'acid' 'acquired' 'act'\n",
      " 'acting' 'action' 'actions' 'active' 'activities' 'activity' 'acts'\n",
      " 'actual' 'actually' 'ad' 'adam' 'adams' 'adaptec' 'adapter' 'add' 'added'\n",
      " 'adding' 'addition' 'additional' 'address' 'addressed' 'addresses'\n",
      " 'addressing' 'adequate' 'adl' 'administration' 'administration official'\n",
      " 'administrator' 'admit' 'admitted' 'adobe' 'ads' 'adult' 'adults'\n",
      " 'advance' 'advanced' 'advantage' 'advertising' 'advice' 'aerospace'\n",
      " 'affairs' 'affect' 'affected' 'afford' 'afraid' 'african']\n"
     ]
    }
   ],
   "source": [
    "# Show some vocabulary terms\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(vocab[200:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d87d0f",
   "metadata": {},
   "source": [
    "### Task 2: Implementing a retrieval function\n",
    "\n",
    "- Converts a query to a TF-IDF vector\n",
    "- Computes cosine similarity with all document vectors\n",
    "- Returns the top-k most similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32dbddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Implement the retrieval function\n",
    "def retrieve_documents(query_text, top_k=10):\n",
    "    # Transform query to TF-IDF vector using the same vectorizer\n",
    "    query_vector = vectorizer.transform([query_text])\n",
    "    \n",
    "    # Compute cosine similarity between query and all documents\n",
    "    # cosine_similarity returns a matrix of shape (1, num_documents)\n",
    "    similarities = cosine_similarity(query_vector, document_vectors).flatten()\n",
    "    \n",
    "    # Get indices of top-k documents (sorted by similarity, descending)\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    # Return a dataframe with the top-k results\n",
    "    df_results = df.iloc[top_indices].copy()\n",
    "    df_results['similarity'] = similarities[top_indices]\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ded750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9137</th>\n",
       "      <td>\\nWhat about the common joystick found in all ...</td>\n",
       "      <td>0.675917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8258</th>\n",
       "      <td>\\n\\nRumor has it that a guy at Dell Computer h...</td>\n",
       "      <td>0.650509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8464</th>\n",
       "      <td>\\n Computers are a special case.. and it's a p...</td>\n",
       "      <td>0.517928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  similarity\n",
       "9137  \\nWhat about the common joystick found in all ...    0.675917\n",
       "8258  \\n\\nRumor has it that a guy at Dell Computer h...    0.650509\n",
       "8464  \\n Computers are a special case.. and it's a p...    0.517928"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results = retrieve_documents(query_text='computer', top_k=3)\n",
    "search_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ed705f",
   "metadata": {},
   "source": [
    "> **Note:** how the top three results are all related to the query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6035e97",
   "metadata": {},
   "source": [
    "## **Student Exercise**: build a search engine on the `CVs` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c02a7082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 40 CVs from 40 JSON files\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "cv_dir = Path(\"../datasets/CVs\")\n",
    "\n",
    "cv_files = sorted(list(cv_dir.rglob(\"*.json\")))  # include everything\n",
    "\n",
    "cvs_text = []\n",
    "cv_names = []\n",
    "\n",
    "for file in cv_files:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    parts = []\n",
    "    for key in [\"Heading\", \"Skills\", \"Projects\", \"Experience\", \"Education\"]:\n",
    "        if key in data and data[key]:\n",
    "            if isinstance(data[key], list):\n",
    "                parts.append(\" \".join(map(str, data[key])))\n",
    "            else:\n",
    "                parts.append(str(data[key]))\n",
    "\n",
    "    text = \" \".join(parts).strip()\n",
    "    if text:\n",
    "        cvs_text.append(text)\n",
    "        cv_names.append(file.stem)\n",
    "\n",
    "print(f\"Loaded {len(cvs_text)} CVs from {len(cv_files)} JSON files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed3a8cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV TF-IDF matrix shape: (40, 3000)\n"
     ]
    }
   ],
   "source": [
    "# STUDENT EXERCISE\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)      # remove urls\n",
    "    text = re.sub(r\"\\S+@\\S+\", \" \", text)      # remove emails\n",
    "    text = re.sub(r\"\\s+\", \" \", text)          # normalize spaces\n",
    "    return text.strip()\n",
    "\n",
    "cvs_processed = [preprocess(t) for t in cvs_text]\n",
    "\n",
    "vectorizer_cv = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    max_features=3000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "cv_tfidf = vectorizer_cv.fit_transform(cvs_processed)\n",
    "\n",
    "print(\"CV TF-IDF matrix shape:\", cv_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d706a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def search_cvs(query, top_k=5):\n",
    "    query_vec = vectorizer_cv.transform([preprocess(query)])\n",
    "    sims = cosine_similarity(query_vec, cv_tfidf).flatten()\n",
    "    top_idx = np.argsort(sims)[::-1][:top_k]\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"CV\": [cv_names[i] for i in top_idx],\n",
    "        \"Similarity\": sims[top_idx]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ae1ef66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_en</td>\n",
       "      <td>0.231124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0.228082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>0.220580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05_en</td>\n",
       "      <td>0.150706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CV  Similarity\n",
       "0  01_en    0.231124\n",
       "1     30    0.228082\n",
       "2     11    0.220580\n",
       "3     15    0.208475\n",
       "4  05_en    0.150706"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_cvs(\"machine learning python model\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dde3ae72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0.384903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02_en</td>\n",
       "      <td>0.323118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>0.244448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>0.219602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0.203542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CV  Similarity\n",
       "0     12    0.384903\n",
       "1  02_en    0.323118\n",
       "2     23    0.244448\n",
       "3     32    0.219602\n",
       "4     24    0.203542"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_cvs(\"business intelligence power bi sql\", top_k=5)\n",
    "search_cvs(\"data engineer aws spark pipeline\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7669ec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV: 01_en\n",
      "Top contributing terms:\n",
      "- learning: 0.0740\n",
      "- model: 0.0526\n",
      "- machine: 0.0473\n",
      "- machine learning: 0.0383\n",
      "- python: 0.0189\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def explain_match(query, doc_index, top_terms=12):\n",
    "    q = preprocess(query)\n",
    "    q_vec = vectorizer_cv.transform([q])\n",
    "    d_vec = cv_tfidf[doc_index]\n",
    "\n",
    "    contrib = (q_vec.multiply(d_vec)).toarray().flatten()\n",
    "    if contrib.sum() == 0:\n",
    "        print(\"No overlapping terms between query and this CV.\")\n",
    "        return\n",
    "\n",
    "    terms = np.array(vectorizer_cv.get_feature_names_out())\n",
    "    top_idx = contrib.argsort()[::-1][:top_terms]\n",
    "    top_idx = top_idx[contrib[top_idx] > 0]\n",
    "\n",
    "    print(\"Top contributing terms:\")\n",
    "    for i in top_idx:\n",
    "        print(f\"- {terms[i]}: {contrib[i]:.4f}\")\n",
    "\n",
    "res = search_cvs(\"machine learning python model\", top_k=5)\n",
    "best_cv_name = res.iloc[0][\"CV\"]\n",
    "best_idx = cv_names.index(best_cv_name)\n",
    "\n",
    "print(\"Best CV:\", best_cv_name)\n",
    "explain_match(\"machine learning python model\", best_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2010ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram: (1, 1)  top similarity: 0.37273861761029986\n",
      "ngram: (1, 2)  top similarity: 0.2995380629867528\n"
     ]
    }
   ],
   "source": [
    "def build_tfidf(ngram=(1,1), max_feat=3000):\n",
    "    vec = TfidfVectorizer(stop_words=\"english\", max_features=max_feat, ngram_range=ngram)\n",
    "    mat = vec.fit_transform(cvs_processed)\n",
    "    return vec, mat\n",
    "\n",
    "for ngram in [(1,1), (1,2)]:\n",
    "    vec_tmp, mat_tmp = build_tfidf(ngram=ngram, max_feat=3000)\n",
    "    qv = vec_tmp.transform([preprocess(\"business intelligence power bi sql\")])\n",
    "    sims = cosine_similarity(qv, mat_tmp).flatten()\n",
    "    print(\"ngram:\", ngram, \" top similarity:\", sims.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cf2d36",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f036631f",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4134f187",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "- **TF-IDF** is a simple but effective method for information retrieval\n",
    "- **Sparse matrices** make TF-IDF scalable to large document collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428874e6",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "- Explore other scikit-learn datasets (e.g., `fetch_20newsgroups` with different subsets)\n",
    "- Try advanced techniques like BM25 (can be implemented with sklearn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
